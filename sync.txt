rsync -a outputs s224075134@rds-storage.deakin.edu.au:/RDS/RDS75807-temporal-diffusion/storage/projects/temporal_diffusion/diffusion-forcing-transformer --info=progress


rsync -a minecraft_latent_32_1cd9pgpb.zip s224075134@rds-storage.deakin.edu.au:/RDS/RDS75807-temporal-diffusion/storage/projects/temporal_diffusion/datasets/video


python -m main '+name=UCF_101_dit3d' 'dataset=ucf_101' 'algorithm=contrastive_dfot_video' 'experiment=video_generation' 'algorithm.contrastive_loss_weight=0' 'algorithm.backbone=null' '++algorithm.backbone.name=dit3d' '++algorithm.backbone.variant=full' '++algorithm.backbone.pos_emb_type=rope_3d' '++algorithm.backbone.patch_size=2' '++algorithm.backbone.hidden_size=384' '++algorithm.backbone.depth=12' '++algorithm.backbone.num_heads=6' '++algorithm.backbone.mlp_ratio=4.0' 'load=/weka/s224075134/temporal_diffusion/diffusion-forcing-transformer/outputs/2025-04-14/14-43-35/checkpoints/epoch\=89-step\=168750.ckpt' experiment.validation.limit_batch=200 experiment.tasks=[validation] '++algorithm.backbone.use_gradient_checkpointing=False'


python -m main +name=single_image_to_short dataset=realestate10k_mini algorithm=dfot_video_pose experiment=video_generation @diffusion/continuous load=pretrained:DFoT_RE10K.ckpt 'experiment.tasks=[validation]' experiment.validation.data.shuffle=True dataset.context_length=1 dataset.frame_skip=20 dataset.n_frames=8 experiment.validation.batch_size=1 algorithm.tasks.prediction.history_guidance.name=vanilla +algorithm.tasks.prediction.history_guidance.guidance_scale=4.0 dataset.max_frames=4 wandb.mode=disabled


python -m main +name=single_image_to_short dataset=ucf_101 algorithm=gibbs_dfot_video experiment=video_generation @DiT/B load= 'experiment.tasks=[validation]' experiment.validation.data.shuffle=False dataset.context_length=4 dataset.frame_skip=1 dataset.n_frames=16 experiment.validation.batch_size=2 algorithm.tasks.prediction.history_guidance.name=conditional wandb.mode=disabled

`python -m main +name=Preprocessing_UCF101 dataset=ucf_101 algorithm=dc_ae_preprocessor experiment=video_latent_preprocessing
`


python -m main +name=single_image_to_short dataset=cond_ucf_101 algorithm=gibbs_dfot_video experiment=video_generation @DiT/B 'load=/home/s224075134/diffusion-forcing-transformer/outputs/outputs/video_generation/training/cond_ucf_101/gibbs_dfot_video/2025-05-03/22-46-34/checkpoints/epoch\=3-step\=150005.ckpt' 'experiment.tasks=[validation]' experiment.validation.data.shuffle=False dataset.context_length=4 dataset.frame_skip=1 dataset.n_frames=16 experiment.validation.batch_size=16 algorithm.tasks.prediction.history_guidance.name=conditional algorithm.logging.validate_generation=False

python -m main +name=training_single_image_to_short dataset=cond_ucf_101 algorithm=dfot_video experiment=video_generation @DiT/B 'load=/home/s224075134/diffusion-forcing-transformer/outputs/outputs/video_generation/training/cond_ucf_101/dfot_video/2025-05-03/07-07-26/checkpoints/last.ckpt' 'experiment.tasks=[validation]' experiment.validation.data.shuffle=False dataset.context_length=4 dataset.frame_skip=1 dataset.n_frames=16 experiment.validation.batch_size=16 algorithm.tasks.prediction.history_guidance.name=conditional


new_argv ['/home/s224075134/diffusion-forcing-transformer/main.py', '+name=16f_dfot_rnn_dit3d_cond_ucf_101', 'dataset=cond_ucf_101', 'algorithm=gibbs_dfot_video', 'experiment=video_generation', 'algorithm.scheduling_matrix=full_sequence', 'algorithm.noise_level=random_independent', 'algorithm.backbone.gibbs.enabled=False', 'algorithm.backbone=null', '++algorithm={backbone: {depth: 12, hidden_size: 768, num_heads: 12, conv_lstm: {hidden_dim: [512, 512, 512], kernel_size: 3, num_layers: 3}}}', 'wandb.mode=disabled']


python -m main +name=single_image_to_short dataset=bair algorithm=dfot_video experiment=video_generation @DiT/B 'load=/home/s224075134/diffusion-forcing-transformer/outputs/outputs/video_generation/training/bair/dfot_video/2025-04-26/14-13-45/checkpoints/last.ckpt' 'experiment.tasks=[validation]' experiment.validation.data.shuffle=False dataset.context_length=0 dataset.frame_skip=1 dataset.n_frames=16 experiment.validation.batch_size=16 algorithm.tasks.prediction.history_guidance.name=conditional algorithm.logging.validate_generation=False


python -m main +name=dmlab_4_to_16 dataset=dmlab algorithm=dfot_video experiment=video_generation @DiT/B 'load=/home/s224075134/diffusion-forcing-transformer/outputs/outputs/video_generation/training/dmlab/dfot_video/2025-05-17/00-07-48/checkpoints/epoch\=0-step\=225000.ckpt' 'experiment.tasks=[validation]' experiment.validation.data.shuffle=False dataset.context_length=4 dataset.frame_skip=1 dataset.n_frames=50 experiment.validation.batch_size=13 algorithm.tasks.prediction.history_guidance.name=conditional wandb.mode=disabled algorithm.diffusion.sampling_timesteps=5


python -m main +name=single_image_to_short dataset=cond_ucf_101 algorithm=dfot_video experiment=video_generation "++algorithm={backbone: {depth: 12, hidden_size: 768, num_heads: 12}}" load=/home/s224075134/diffusion-forcing-transformer/outputs/outputs/video_generation/training/cond_ucf_101/dfot_video/2025-05-14/22-09-27/checkpoints/last.ckpt experiment.tasks=[validation] experiment.validation.data.shuffle=False dataset.context_length=4 dataset.frame_skip=1 dataset.n_frames=16 experiment.validation.batch_size=16 algorithm.tasks.prediction.history_guidance.name=conditional


python -m main +name=ucf_101_0_to_16 dataset=cond_ucf_101 algorithm=dfot_video experiment=video_generation "++algorithm={backbone: {depth: 12, hidden_size: 768, num_heads: 12}}" load=/scratch/s224075134/temporal_diffusion/diffusion-forcing-transformer/outputs/video_generation/training/cond_ucf_101/dfot_video/2025-05-14/22-09-27/checkpoints/last.ckpt experiment.tasks=[validation] experiment.validation.data.shuffle=False dataset.context_length=4 dataset.frame_skip=1 dataset.n_frames=16 experiment.validation.batch_size=16 algorithm.tasks.prediction.history_guidance.name=conditional experiment.validation.limit_batch=256


python -m main +name=single_image_to_short dataset=cond_ucf_101_scaling algorithm=dfot_video experiment=video_generation "++algorithm={backbone: {depth: 12, hidden_size: 768, num_heads: 12}}" load=/home/s224075134/diffusion-forcing-transformer/outputs/outputs/video_generation/training/cond_ucf_101_scaling/dfot_video/2025-05-16/17-30-31/checkpoints/last.ckpt experiment.tasks=[validation] experiment.validation.data.shuffle=False dataset.context_length=4 dataset.frame_skip=1 dataset.n_frames=16 experiment.validation.batch_size=16 algorithm.tasks.prediction.history_guidance.name=conditional


python -m main +name=difference_reference_dfot_cond_ucf_101_4_to_16 dataset=cond_ucf_101 algorithm=reference_dfot_video experiment=video_generation "++algorithm={backbone: {depth: 12, hidden_size: 768, num_heads: 12}}" load=/scratch/s224075134/temporal_diffusion/diffusion-forcing-transformer/outputs/video_generation/training/cond_ucf_101/reference_dfot_video/2025-05-21/18-48-58/checkpoints/last.ckpt experiment.tasks=[validation] experiment.validation.data.shuffle=False dataset.context_length=0 dataset.frame_skip=1 dataset.n_frames=16 experiment.validation.batch_size=16 algorithm.tasks.prediction.history_guidance.name=conditional algorithm.reference.predict_difference=True experiment.validation.limit_batch=256


# Preprocess to latent
## DMLab
python -m main +name=Preprocessing_DMLAB dataset=dmlab algorithm=kl_autoencoder_preprocessor experiment=video_latent_preprocessing wandb.mode=disabled
## UCF101
python -m main +name=Preprocessing_UCF101 dataset=ucf_101 algorithm=kl_autoencoder_preprocessor experiment=video_latent_preprocessing wandb.mode=disabled

# Training

## Pixel

## Latent
### DMLab
python -m main '+name=latent_16f_dfot_dmlab' 'dataset=dmlab' 'algorithm=dfot_video' 'experiment=video_generation' '++algorithm={backbone: {depth: 12, hidden_size: 768, num_heads: 12}}' dataset.max_frames=16 experiment.training.batch_size=16 experiment.validation.batch_size=16
