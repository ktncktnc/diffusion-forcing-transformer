{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4df64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s224075134/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/s224075134/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import hydra\n",
    "import torch\n",
    "from experiments.video_generation import VideoGenerationExperiment\n",
    "from einops import rearrange\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9134d079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s224075134/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hydra': {'run': {'dir': '${output_dir}/${now:%Y-%m-%d}/${now:%H-%M-%S}'}, 'sweep': {'dir': 'multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}', 'subdir': '${hydra.job.num}'}, 'launcher': {'_target_': 'hydra._internal.core_plugins.basic_launcher.BasicLauncher'}, 'sweeper': {'_target_': 'hydra._internal.core_plugins.basic_sweeper.BasicSweeper', 'max_batch_size': None, 'params': None}, 'help': {'app_name': '${hydra.job.name}', 'header': '${hydra.help.app_name} is powered by Hydra.\\n', 'footer': 'Powered by Hydra (https://hydra.cc)\\nUse --hydra-help to view Hydra specific help\\n', 'template': '${hydra.help.header}\\n== Configuration groups ==\\nCompose your configuration from those groups (group=option)\\n\\n$APP_CONFIG_GROUPS\\n\\n== Config ==\\nOverride anything in the config (foo.bar=value)\\n\\n$CONFIG\\n\\n${hydra.help.footer}\\n'}, 'hydra_help': {'template': \"Hydra (${hydra.runtime.version})\\nSee https://hydra.cc for more info.\\n\\n== Flags ==\\n$FLAGS_HELP\\n\\n== Configuration groups ==\\nCompose your configuration from those groups (For example, append hydra/job_logging=disabled to command line)\\n\\n$HYDRA_CONFIG_GROUPS\\n\\nUse '--cfg hydra' to Show the Hydra config.\\n\", 'hydra_help': '???'}, 'hydra_logging': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][HYDRA] %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}}, 'root': {'level': 'INFO', 'handlers': ['console']}, 'loggers': {'logging_example': {'level': 'DEBUG'}}, 'disable_existing_loggers': False}, 'job_logging': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': '${hydra.runtime.output_dir}/${hydra.job.name}.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}, 'env': {}, 'mode': None, 'searchpath': [], 'callbacks': {}, 'output_subdir': '.hydra', 'overrides': {'hydra': [], 'task': ['algorithm=contrastive_dfot_video', 'experiment=video_generation', 'dataset=ucf_101', 'experiment.tasks=[validation]', 'experiment.validation.data.shuffle=False', 'dataset.context_length=4', 'dataset.n_frames=12', 'experiment.validation.batch_size=4', 'algorithm.tasks.prediction.history_guidance.name=vanilla', '++algorithm.backbone.name=u_net3d', '++algorithm.backbone.network_size=48', '++algorithm.backbone.num_res_blocks=2', '++algorithm.backbone.resnet_block_groups=8', '++algorithm.backbone.dim_mults=[1, 2, 4, 8]', '++algorithm.backbone.attn_resolutions=[8, 16, 32, 64]', '++algorithm.backbone.attn_dim_head=32', '++algorithm.backbone.attn_heads=4', '++algorithm.backbone.use_linear_attn=True', '++algorithm.backbone.use_init_temporal_attn=True', '++algorithm.backbone.init_kernel_size=7', '++algorithm.backbone.dropout=0.0 ']}, 'job': {'name': 'notebook', 'chdir': None, 'override_dirname': '++algorithm.backbone.attn_dim_head=32,++algorithm.backbone.attn_heads=4,++algorithm.backbone.attn_resolutions=[8, 16, 32, 64],++algorithm.backbone.dim_mults=[1, 2, 4, 8],++algorithm.backbone.dropout=0.0 ,++algorithm.backbone.init_kernel_size=7,++algorithm.backbone.name=u_net3d,++algorithm.backbone.network_size=48,++algorithm.backbone.num_res_blocks=2,++algorithm.backbone.resnet_block_groups=8,++algorithm.backbone.use_init_temporal_attn=True,++algorithm.backbone.use_linear_attn=True,algorithm.tasks.prediction.history_guidance.name=vanilla,algorithm=contrastive_dfot_video,dataset.context_length=4,dataset.n_frames=12,dataset=ucf_101,experiment.tasks=[validation],experiment.validation.batch_size=4,experiment.validation.data.shuffle=False,experiment=video_generation', 'id': '???', 'num': '???', 'config_name': 'config', 'env_set': {}, 'env_copy': [], 'config': {'override_dirname': {'kv_sep': '=', 'item_sep': ',', 'exclude_keys': []}}}, 'runtime': {'version': '1.3.2', 'version_base': '1.3', 'cwd': '/home/s224075134/diffusion-forcing-transformer/test', 'config_sources': [{'path': 'hydra.conf', 'schema': 'pkg', 'provider': 'hydra'}, {'path': '/home/s224075134/diffusion-forcing-transformer/configurations', 'schema': 'file', 'provider': 'main'}, {'path': '', 'schema': 'structured', 'provider': 'schema'}], 'output_dir': '???', 'choices': {'cluster': None, 'algorithm': 'contrastive_dfot_video', 'algorithm/backbone': 'dit3d', 'dataset': 'ucf_101', 'experiment': 'video_generation', 'dataset_experiment': 'ucf_101_video_generation', 'dataset_experiment/../algorithm/backbone@algorithm.backbone': 'dit3d', 'hydra/env': 'default', 'hydra/callbacks': None, 'hydra/job_logging': 'default', 'hydra/hydra_logging': 'default', 'hydra/hydra_help': 'default', 'hydra/help': 'default', 'hydra/sweeper': 'basic', 'hydra/launcher': 'basic', 'hydra/output': 'default'}}, 'verbose': False}, 'experiment': {'debug': '${debug}', 'tasks': ['validation'], 'num_nodes': 1, 'training': {'precision': '16-mixed', 'compile': False, 'lr': 0.0001, 'batch_size': 16, 'max_epochs': 100, 'max_steps': -1, 'max_time': None, 'data': {'num_workers': 11, 'shuffle': False}, 'optim': {'accumulate_grad_batches': 1, 'gradient_clip_val': 1.0}, 'checkpointing': {'every_n_train_steps': None, 'every_n_epochs': 2, 'train_time_interval': None, 'enable_version_counter': False}}, 'validation': {'precision': '16-mixed', 'compile': False, 'batch_size': 4, 'val_every_n_step': 1.0, 'val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'limit_batch': 10, 'data': {'num_workers': 1, 'shuffle': False}, 'inference_mode': True}, 'test': {'precision': '16-mixed', 'compile': False, 'batch_size': 16, 'limit_batch': 1.0, 'data': {'num_workers': 1, 'shuffle': False}, 'inference_mode': True}, 'find_unused_parameters': False, 'reload_dataloaders_every_n_epochs': 1, 'ema': {'enable': True, 'decay': 0.999, 'validate_original_weights': False}, '_name': 'video_generation'}, 'dataset': {'debug': '${debug}', 'save_dir': '/weka/s224075134/temporal_diffusion/datasets/video/ucf101', 'data_mean': [[[0.3965]], [[0.3754]], [[0.3503]]], 'data_std': [[[0.2725]], [[0.2665]], [[0.2717]]], 'latent': {'enable': False, 'type': 'pre_sample', 'suffix': None, 'downsampling_factor': [1, 8], 'num_channels': 4}, 'resolution': 64, 'observation_shape': [3, '${dataset.resolution}', '${dataset.resolution}'], 'max_frames': 32, 'n_frames': 12, 'context_length': 4, 'frame_skip': 1, 'filter_min_len': None, 'external_cond_dim': 0, 'external_cond_stack': False, 'external_cond_processing': None, 'preload': False, 'subdataset_size': 30000, 'num_eval_videos': 6144, 'video_preprocessing': 'mp4', 'augmentation': {'p': 1.0, 'xflip': 0.5, 'yflip': 0.5, 'rotate_int': 0.5, 'translate_int': 0.5, 'scale': 0.3, 'contrast': 0.125, 'brightness': 0.3, 'lumaflip': 0.5, 'hue': 0.3, 'saturation': 0.3}, '_name': 'ucf_101'}, 'algorithm': {'debug': '${debug}', 'lr': '${experiment.training.lr}', 'backbone': {'name': 'u_net3d', 'variant': 'full', 'pos_emb_type': 'rope_3d', 'patch_size': 2, 'hidden_size': 384, 'depth': 12, 'num_heads': 6, 'mlp_ratio': 4.0, 'use_gradient_checkpointing': True, 'network_size': 48, 'num_res_blocks': 2, 'resnet_block_groups': 8, 'dim_mults': [1, 2, 4, 8], 'attn_resolutions': [8, 16, 32, 64], 'attn_dim_head': 32, 'attn_heads': 4, 'use_linear_attn': True, 'use_init_temporal_attn': True, 'init_kernel_size': 7, 'dropout': 0.0}, 'x_shape': '${dataset.observation_shape}', 'max_frames': '${dataset.max_frames}', 'n_frames': '${dataset.n_frames}', 'frame_skip': '${dataset.frame_skip}', 'context_frames': '${dataset.context_length}', 'latent': '${dataset.latent}', 'data_mean': '${dataset.data_mean}', 'data_std': '${dataset.data_std}', 'external_cond_dim': '${dataset.external_cond_dim}', 'external_cond_stack': '${dataset.external_cond_stack}', 'external_cond_processing': '${dataset.external_cond_processing}', 'compile': False, 'weight_decay': 0, 'optimizer_beta': [0.9, 0.99], 'lr_scheduler': {'name': 'constant_with_warmup', 'num_warmup_steps': 10000}, 'noise_level': 'random_independent', 'uniform_future': {'enabled': False}, 'fixed_context': {'enabled': False, 'indices': None, 'dropout': 0}, 'variable_context': {'enabled': False, 'prob': 0, 'dropout': 0}, 'chunk_size': -1, 'scheduling_matrix': 'full_sequence', 'replacement': 'noisy_scale', 'diffusion': {'is_continuous': False, 'timesteps': 1000, 'beta_schedule': 'cosine', 'schedule_fn_kwargs': {'shift': 1.0}, 'use_causal_mask': False, 'clip_noise': 20.0, 'objective': 'pred_v', 'loss_weighting': {'strategy': 'fused_min_snr', 'snr_clip': 5.0, 'cum_snr_decay': 0.96}, 'sampling_timesteps': 50, 'ddim_sampling_eta': 0.0, 'reconstruction_guidance': 0.0, 'same_noise_on_all_frames': False}, 'vae': {'pretrained_path': None, 'pretrained_kwargs': {}, 'use_fp16': True, 'batch_size': 2}, 'checkpoint': {'reset_optimizer': False, 'strict': True}, 'tasks': {'prediction': {'enabled': True, 'history_guidance': {'name': 'vanilla'}, 'keyframe_density': None, 'sliding_context_len': None}, 'interpolation': {'enabled': False, 'history_guidance': {'name': 'conditional'}, 'max_batch_size': None}}, 'logging': {'deterministic': 0, 'loss_freq': 100, 'grad_norm_freq': 100, 'max_num_videos': 128, 'n_metrics_frames': 16, 'metrics': ['vbench', 'fvd', 'is', 'fid', 'lpips', 'mse', 'ssim', 'psnr'], 'metrics_batch_size': 16, 'sanity_generation': False, 'raw_dir': None}, 'save_representation': False, 'representation_dir': '${output_dir}/representations', 'contrastive_clip_frames': 8, 'diffusion_clip_frames': 16, 'contrastive_loss_weight': 0.3, '_name': 'contrastive_dfot_video'}, 'debug': False, 'wandb': {'entity': 'ktncktnc1', 'project': 'dfot', 'mode': 'online'}, 'output_dir': '/weka/s224075134/temporal_diffusion/diffusion-forcing-transformer/outputs', 'resume': None, 'load': None}\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from omegaconf import DictConfig\n",
    "from omegaconf.omegaconf import open_dict\n",
    "# Initialize Hydra\n",
    "# The version_base is optional but recommended to avoid deprecation warnings\n",
    "with initialize(version_base=None, config_path=\"../configurations\"):\n",
    "    # Compose the config - replace \"config_name\" with your actual config name\n",
    "    # You can also override values here if needed\n",
    "    cfg = compose(\n",
    "        config_name=\"config\", \n",
    "        overrides=[\n",
    "            'algorithm=contrastive_dfot_video', \n",
    "            \"experiment=video_generation\",\n",
    "            'dataset=ucf_101',\n",
    "            'experiment.tasks=[validation]',\n",
    "            'experiment.validation.data.shuffle=False',\n",
    "            'dataset.context_length=4',\n",
    "            'dataset.n_frames=12',\n",
    "            'experiment.validation.batch_size=4',\n",
    "            'algorithm.tasks.prediction.history_guidance.name=vanilla',\n",
    "            '++algorithm.backbone.name=u_net3d', \n",
    "            '++algorithm.backbone.network_size=48', \n",
    "            '++algorithm.backbone.num_res_blocks=2', \n",
    "            '++algorithm.backbone.resnet_block_groups=8', \n",
    "            '++algorithm.backbone.dim_mults=[1, 2, 4, 8]', \n",
    "            '++algorithm.backbone.attn_resolutions=[8, 16, 32, 64]', \n",
    "            '++algorithm.backbone.attn_dim_head=32', \n",
    "            '++algorithm.backbone.attn_heads=4', \n",
    "            '++algorithm.backbone.use_linear_attn=True', \n",
    "            '++algorithm.backbone.use_init_temporal_attn=True', \n",
    "            '++algorithm.backbone.init_kernel_size=7', \n",
    "            '++algorithm.backbone.dropout=0.0 ' \n",
    "            ],\n",
    "        return_hydra_config=True\n",
    "    )\n",
    "    \n",
    "    # Now you have the config in the 'cfg' variable\n",
    "    # You can print it, access values, etc. without running your actual application\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "    \n",
    "    # Access config values\n",
    "    # print(f\"Some value from config: {cfg.some_key}\")\n",
    "cfg_choice = cfg['hydra'].runtime.choices\n",
    "with open_dict(cfg):\n",
    "    if cfg_choice[\"experiment\"] is not None:\n",
    "        cfg.experiment._name = cfg_choice[\"experiment\"]\n",
    "    if cfg_choice[\"dataset\"] is not None:\n",
    "        cfg.dataset._name = cfg_choice[\"dataset\"]\n",
    "    if cfg_choice[\"algorithm\"] is not None:\n",
    "        cfg.algorithm._name = cfg_choice[\"algorithm\"]\n",
    "    \n",
    "\n",
    "exp = VideoGenerationExperiment(cfg, None, None)\n",
    "algo = exp._build_algo()\n",
    "algo = algo.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4142a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s224075134/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:166: UserWarning: Memory efficient kernel not used because: (Triggered internally at /pytorch/aten/src/ATen/native/transformers/cuda/sdp_utils.cpp:776.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "/home/s224075134/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:166: UserWarning: Memory Efficient attention has been runtime disabled. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/sdp_utils_cpp.h:551.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "/home/s224075134/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:166: UserWarning: Flash attention kernel not used because: (Triggered internally at /pytorch/aten/src/ATen/native/transformers/cuda/sdp_utils.cpp:778.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "/home/s224075134/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:166: UserWarning: Expected query, key and value to all be of dtype: {Half, BFloat16}. Got Query dtype: float, Key dtype: float, and Value dtype: float instead. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/sdp_utils_cpp.h:93.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "/home/s224075134/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:166: UserWarning: CuDNN attention kernel not used because: (Triggered internally at /pytorch/aten/src/ATen/native/transformers/cuda/sdp_utils.cpp:780.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n",
      "/home/s224075134/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:166: UserWarning: CuDNN attention has been runtime disabled. (Triggered internally at /pytorch/aten/src/ATen/native/transformers/cuda/sdp_utils.cpp:528.)\n",
      "  hidden_states = F.scaled_dot_product_attention(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No available kernel. Aborting execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m k \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1000\u001b[39m, (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m12\u001b[39m))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net3d.py:199\u001b[0m, in \u001b[0;36mUnet3D.forward\u001b[0;34m(self, x, noise_levels, external_cond, external_cond_mask, return_representation)\u001b[0m\n\u001b[1;32m    196\u001b[0m     emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([emb, external_cond_emb], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    198\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_conv(x)\n\u001b[0;32m--> 199\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_temporal_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m h \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    202\u001b[0m hs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:339\u001b[0m, in \u001b[0;36mUnetTemporalAttentionBlock.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attn_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     attn_mask \u001b[38;5;241m=\u001b[39m repeat(\n\u001b[1;32m    337\u001b[0m         attn_mask, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb t1 t2 -> (b h w) t1 t2\u001b[39m\u001b[38;5;124m\"\u001b[39m, h\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], w\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    338\u001b[0m     )\n\u001b[0;32m--> 339\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:319\u001b[0m, in \u001b[0;36mget_einops_wrapped_module.<locals>.WrappedModule.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:307\u001b[0m, in \u001b[0;36mEinopsWrapper.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m axes_lengths \u001b[38;5;241m=\u001b[39m parse_shape(x, pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_shape)\n\u001b[1;32m    306\u001b[0m x \u001b[38;5;241m=\u001b[39m rearrange(x, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 307\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m x \u001b[38;5;241m=\u001b[39m rearrange(x, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths)\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:293\u001b[0m, in \u001b[0;36mTemporalAttentionBlock.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    289\u001b[0m     time_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_pos_embedding(\n\u001b[1;32m    290\u001b[0m         torch\u001b[38;5;241m.\u001b[39marange(num_frames, device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m time_emb\n\u001b[0;32m--> 293\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:210\u001b[0m, in \u001b[0;36mAttentionBlock.forward\u001b[0;34m(self, x, is_causal, attn_mask)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    206\u001b[0m     x: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    207\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    208\u001b[0m     attn_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/diffusion-forcing-transformer/test/../algorithms/contrastive_dfot/backbones/u_net/u_net_blocks.py:166\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, hidden_states, is_causal, attn_mask)\u001b[0m\n\u001b[1;32m    162\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: t\u001b[38;5;241m.\u001b[39mcontiguous(), (q, k, v))\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sdpa_kernel(backends\u001b[38;5;241m=\u001b[39mbackends):\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# pylint: disable=E1102\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m rearrange(hidden_states, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb h n d -> b n (h d)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(q\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No available kernel. Aborting execution."
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 12, 3, 64, 64).to('cuda:0')\n",
    "k = torch.randint(0, 1000, (4, 12)).to('cuda:0')\n",
    "output = algo.diffusion_model.model(x, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0dac586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet3D(\n",
       "  (noise_level_pos_embedding): StochasticTimeEmbedding(\n",
       "    (timesteps): StochasticUnknownTimesteps()\n",
       "    (embedding): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=48, out_features=192, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=192, out_features=192, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (init_conv): Conv3d(3, 48, kernel_size=(1, 7, 7), stride=(1, 1, 1), padding=(0, 3, 3))\n",
       "  (rotary_time_pos_embedding): RotaryEmbedding()\n",
       "  (init_temporal_attn): UnetTemporalAttentionBlock(\n",
       "    (wrapper): EinopsWrapper(\n",
       "      (module): TemporalAttentionBlock(\n",
       "        (attn_block): AttentionBlock(\n",
       "          (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (rotary_emb): RotaryEmbedding()\n",
       "            (to_qkv): Linear(in_features=48, out_features=384, bias=False)\n",
       "            (to_out): Linear(in_features=128, out_features=48, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): UnetSequential(\n",
       "        (0): ResnetBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=192, out_features=96, bias=True)\n",
       "          )\n",
       "          (skip_conv): Identity()\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=192, out_features=96, bias=True)\n",
       "          )\n",
       "          (skip_conv): Identity()\n",
       "        )\n",
       "        (2): WrappedModule(\n",
       "          (wrapper): EinopsWrapper(\n",
       "            (module): AttentionBlock(\n",
       "              (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): LinearAttention(\n",
       "                (to_qkv): Linear(in_features=48, out_features=384, bias=False)\n",
       "                (to_out): Linear(in_features=128, out_features=48, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): UnetTemporalAttentionBlock(\n",
       "          (wrapper): EinopsWrapper(\n",
       "            (module): TemporalAttentionBlock(\n",
       "              (attn_block): AttentionBlock(\n",
       "                (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): Attention(\n",
       "                  (rotary_emb): RotaryEmbedding()\n",
       "                  (to_qkv): Linear(in_features=48, out_features=384, bias=False)\n",
       "                  (to_out): Linear(in_features=128, out_features=48, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Downsample(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): UnetSequential(\n",
       "        (0): ResnetBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(48, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (skip_conv): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=192, out_features=192, bias=True)\n",
       "          )\n",
       "          (skip_conv): Identity()\n",
       "        )\n",
       "        (2): WrappedModule(\n",
       "          (wrapper): EinopsWrapper(\n",
       "            (module): AttentionBlock(\n",
       "              (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): LinearAttention(\n",
       "                (to_qkv): Linear(in_features=96, out_features=384, bias=False)\n",
       "                (to_out): Linear(in_features=128, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): UnetTemporalAttentionBlock(\n",
       "          (wrapper): EinopsWrapper(\n",
       "            (module): TemporalAttentionBlock(\n",
       "              (attn_block): AttentionBlock(\n",
       "                (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): Attention(\n",
       "                  (rotary_emb): RotaryEmbedding()\n",
       "                  (to_qkv): Linear(in_features=96, out_features=384, bias=False)\n",
       "                  (to_out): Linear(in_features=128, out_features=96, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Downsample(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): UnetSequential(\n",
       "        (0): ResnetBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(96, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm(8, 192, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=192, out_features=384, bias=True)\n",
       "          )\n",
       "          (skip_conv): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm(8, 192, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm(8, 192, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=192, out_features=384, bias=True)\n",
       "          )\n",
       "          (skip_conv): Identity()\n",
       "        )\n",
       "        (2): WrappedModule(\n",
       "          (wrapper): EinopsWrapper(\n",
       "            (module): AttentionBlock(\n",
       "              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): LinearAttention(\n",
       "                (to_qkv): Linear(in_features=192, out_features=384, bias=False)\n",
       "                (to_out): Linear(in_features=128, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): UnetTemporalAttentionBlock(\n",
       "          (wrapper): EinopsWrapper(\n",
       "            (module): TemporalAttentionBlock(\n",
       "              (attn_block): AttentionBlock(\n",
       "                (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): Attention(\n",
       "                  (rotary_emb): RotaryEmbedding()\n",
       "                  (to_qkv): Linear(in_features=192, out_features=384, bias=False)\n",
       "                  (to_out): Linear(in_features=128, out_features=192, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Downsample(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): UnetSequential(\n",
       "        (0): ResnetBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm(8, 192, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(192, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm(8, 384, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(384, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          )\n",
       "          (skip_conv): Conv3d(192, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock(\n",
       "          (in_layers): Sequential(\n",
       "            (0): GroupNorm(8, 384, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(384, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (out_layers): Sequential(\n",
       "            (0): GroupNorm(8, 384, eps=1e-06, affine=True)\n",
       "            (1): SiLU()\n",
       "            (2): Conv3d(384, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "          )\n",
       "          (emb_layers): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=192, out_features=768, bias=True)\n",
       "          )\n",
       "          (skip_conv): Identity()\n",
       "        )\n",
       "        (2): WrappedModule(\n",
       "          (wrapper): EinopsWrapper(\n",
       "            (module): AttentionBlock(\n",
       "              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): Attention(\n",
       "                (to_qkv): Linear(in_features=384, out_features=384, bias=False)\n",
       "                (to_out): Linear(in_features=128, out_features=384, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): UnetTemporalAttentionBlock(\n",
       "          (wrapper): EinopsWrapper(\n",
       "            (module): TemporalAttentionBlock(\n",
       "              (attn_block): AttentionBlock(\n",
       "                (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn): Attention(\n",
       "                  (rotary_emb): RotaryEmbedding()\n",
       "                  (to_qkv): Linear(in_features=384, out_features=384, bias=False)\n",
       "                  (to_out): Linear(in_features=128, out_features=384, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Identity()\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UnetSequential(\n",
       "      (0): ResnetBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm(8, 768, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(768, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm(8, 192, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=192, out_features=384, bias=True)\n",
       "        )\n",
       "        (skip_conv): Conv3d(768, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): ResnetBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm(8, 192, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm(8, 192, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=192, out_features=384, bias=True)\n",
       "        )\n",
       "        (skip_conv): Identity()\n",
       "      )\n",
       "      (2): WrappedModule(\n",
       "        (wrapper): EinopsWrapper(\n",
       "          (module): AttentionBlock(\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (to_qkv): Linear(in_features=192, out_features=384, bias=False)\n",
       "              (to_out): Linear(in_features=128, out_features=192, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UnetTemporalAttentionBlock(\n",
       "        (wrapper): EinopsWrapper(\n",
       "          (module): TemporalAttentionBlock(\n",
       "            (attn_block): AttentionBlock(\n",
       "              (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): Attention(\n",
       "                (rotary_emb): RotaryEmbedding()\n",
       "                (to_qkv): Linear(in_features=192, out_features=384, bias=False)\n",
       "                (to_out): Linear(in_features=128, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Upsample(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): UnetSequential(\n",
       "      (0): ResnetBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm(8, 384, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(384, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (skip_conv): Conv3d(384, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): ResnetBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=192, out_features=192, bias=True)\n",
       "        )\n",
       "        (skip_conv): Identity()\n",
       "      )\n",
       "      (2): WrappedModule(\n",
       "        (wrapper): EinopsWrapper(\n",
       "          (module): AttentionBlock(\n",
       "            (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): LinearAttention(\n",
       "              (to_qkv): Linear(in_features=96, out_features=384, bias=False)\n",
       "              (to_out): Linear(in_features=128, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UnetTemporalAttentionBlock(\n",
       "        (wrapper): EinopsWrapper(\n",
       "          (module): TemporalAttentionBlock(\n",
       "            (attn_block): AttentionBlock(\n",
       "              (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): Attention(\n",
       "                (rotary_emb): RotaryEmbedding()\n",
       "                (to_qkv): Linear(in_features=96, out_features=384, bias=False)\n",
       "                (to_out): Linear(in_features=128, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Upsample(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): UnetSequential(\n",
       "      (0): ResnetBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm(8, 192, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(192, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=192, out_features=96, bias=True)\n",
       "        )\n",
       "        (skip_conv): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): ResnetBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=192, out_features=96, bias=True)\n",
       "        )\n",
       "        (skip_conv): Identity()\n",
       "      )\n",
       "      (2): WrappedModule(\n",
       "        (wrapper): EinopsWrapper(\n",
       "          (module): AttentionBlock(\n",
       "            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): LinearAttention(\n",
       "              (to_qkv): Linear(in_features=48, out_features=384, bias=False)\n",
       "              (to_out): Linear(in_features=128, out_features=48, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UnetTemporalAttentionBlock(\n",
       "        (wrapper): EinopsWrapper(\n",
       "          (module): TemporalAttentionBlock(\n",
       "            (attn_block): AttentionBlock(\n",
       "              (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): Attention(\n",
       "                (rotary_emb): RotaryEmbedding()\n",
       "                (to_qkv): Linear(in_features=48, out_features=384, bias=False)\n",
       "                (to_out): Linear(in_features=128, out_features=48, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Upsample(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): UnetSequential(\n",
       "      (0): ResnetBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(96, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=192, out_features=96, bias=True)\n",
       "        )\n",
       "        (skip_conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      )\n",
       "      (1): ResnetBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=192, out_features=96, bias=True)\n",
       "        )\n",
       "        (skip_conv): Identity()\n",
       "      )\n",
       "      (2): WrappedModule(\n",
       "        (wrapper): EinopsWrapper(\n",
       "          (module): AttentionBlock(\n",
       "            (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): LinearAttention(\n",
       "              (to_qkv): Linear(in_features=48, out_features=384, bias=False)\n",
       "              (to_out): Linear(in_features=128, out_features=48, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): UnetTemporalAttentionBlock(\n",
       "        (wrapper): EinopsWrapper(\n",
       "          (module): TemporalAttentionBlock(\n",
       "            (attn_block): AttentionBlock(\n",
       "              (norm): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn): Attention(\n",
       "                (rotary_emb): RotaryEmbedding()\n",
       "                (to_qkv): Linear(in_features=48, out_features=384, bias=False)\n",
       "                (to_out): Linear(in_features=128, out_features=48, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Identity()\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UnetSequential(\n",
       "    (0): ResnetBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm(8, 384, eps=1e-06, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv3d(384, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm(8, 384, eps=1e-06, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv3d(384, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      )\n",
       "      (skip_conv): Identity()\n",
       "    )\n",
       "    (1): WrappedModule(\n",
       "      (wrapper): EinopsWrapper(\n",
       "        (module): AttentionBlock(\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (to_qkv): Linear(in_features=384, out_features=384, bias=False)\n",
       "            (to_out): Linear(in_features=128, out_features=384, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UnetTemporalAttentionBlock(\n",
       "      (wrapper): EinopsWrapper(\n",
       "        (module): TemporalAttentionBlock(\n",
       "          (attn_block): AttentionBlock(\n",
       "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (rotary_emb): RotaryEmbedding()\n",
       "              (to_qkv): Linear(in_features=384, out_features=384, bias=False)\n",
       "              (to_out): Linear(in_features=128, out_features=384, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResnetBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm(8, 384, eps=1e-06, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv3d(384, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm(8, 384, eps=1e-06, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv3d(384, 384, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=192, out_features=768, bias=True)\n",
       "      )\n",
       "      (skip_conv): Identity()\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv3d(96, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "      (skip_conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (1): Conv3d(48, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (contrastive_projection): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm(8, 96, eps=1e-06, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv3d(96, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm(8, 48, eps=1e-06, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv3d(48, 48, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
       "      )\n",
       "      (skip_conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (1): Conv3d(48, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.diffusion_model.model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
